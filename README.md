# Vivek Basavanth Hanagoji

**Location:** Boston, MA (Open to Relocate)  
**Phone:** +1 (617)-368 0288  
**Email:** hanagojivivek@gmail.com  
**LinkedIn:** [LinkedIn](https://www.linkedin.com/in/vivekhanagoji)  
**GitHub:** [GitHub](https://github.com/vivekhanagoji)

## Summary üìä

Experienced Data Analyst with a solid 3 years background in IT. Proven expertise in Python for data ingestion, transformation, and analysis. Eager to apply analytical skills and technical knowledge in a Data Analytics and Engineering role starting May 2024.

## About me
![Image](/assets/images/profile.jpg)

üëã Hello, I'm Vivek Basavanth Hanagoji!

üéì I'm a graduate student at Northeastern University, pursuing my Master's degree in Information Systems with a specialization in Data Analytics and Engineering. I'm passionate about leveraging data to drive insights and create meaningful solutions.

üíª My technical skills include proficiency in programming languages such as Python, R, and JavaScript. I have hands-on experience with various database systems, including MySQL, SQL Server, PostgreSQL, MongoDB, Oracle DB, Redshift, and NoSQL. I excel in ETL data modeling, data warehousing, data wrangling, and both descriptive and inferential statistics. I'm also well-versed in data visualization tools like PowerBI and Tableau.

‚òÅÔ∏è I have a strong background in working with data cloud services, including GCP, AWS, Amazon S3, Amazon EC2, AWS Lambda, and Microsoft Azure. I am skilled in data tools such as Alteryx, Talend (ETL tool), ER Studios, Airflow, Snowflake, and Navicat Data Modeler. My software proficiency extends to Git, Jenkins, JIRA, Kafka, Airflow, Docker, Kubernetes, Salesforce, and MATLAB.

üåü I have a proven track record of success in Salesforce analytics and administration, where I've applied my skills to enhance CRM activities and data quality significantly. My projects demonstrate my ability to optimize data processes and deliver actionable insights, which is evident in my work on custom ETL solutions and streamlining data entry processes.

üìä I'm passionate about data-driven decision-making and have worked on a variety of projects, including New York City Motor Vehicle Collision analysis, American Restaurants Food Inspections, Second-hand Car Price Prediction, and an Emotion-Based Music Player. These projects showcase my expertise in data analysis, ETL workflows, and predictive modeling.

## Education üéì

- **Northeastern University**  
  Master of Science in Information Systems  
  _Expected May 2024_  
  Boston, MA

- **Savitribai Phule Pune University**  
  Bachelor of Engineering in Electronics & Tele-Communication  
  _Jul 2015 ‚Äì Jun 2019_  
  Pune, India

## Professional Experience üíº

### Data Analyst  
**Vodafone Intelligent Solutions**  
_Jul 2020 ‚Äì Jun 2022_  
Pune, India

- Engineered and deployed custom ETL solutions for Salesforce, efficiently transferring over 5 TB of critical customer data into Salesforce, with increased data processing speed by 40% and enhancing data quality for CRM activities.
- Developed Business Intelligence solutions by building scalable ETL data pipelines on Snowflake, AWS S3, and Salesforce databases to automate month-end reports & provide ad-hoc data solutions reducing turnaround time by 45%.
- Administered Salesforce Tableau CRM, which entailed extraction of data from Salesforce, development of datasets with dataflows and dataflow builder, and execution, scheduling, and tracking of dataflows.
- Demonstrated success in leading and participating in 30+ Agile sprints, ensuring timely delivery of project milestones and fostering a collaborative team environment for productivity, attaining a 100% on-time delivery rate.
- Utilized Workbench and Salesforce Object Query Language (SOQL) for advanced data patching, correcting over 5,000 records with discrepancies during year-end activities, enhancing data reliability by 45%.

### Salesforce Administrator  
**Vodafone Intelligent Solutions**  
_Jul 2019 ‚Äì Jun 2020_  
Pune, India

- Streamlined data entry processes by 20% by implementing data validation rules and custom fields in Salesforce.
- Utilized tools like Process Builder, Email Templates, Workflow Rules, Workflow Actions, and Approval Flows to improve system functionality, ensuring overall Salesforce efficiency.
- Automated complex data patching processes using Apex Data Loader, processing over 10,000 records monthly, resulting in a 50% reduction in manual data entry errors and a 30% increase in process efficiency.

## Data Science Projects üîß

### Generating Fake Images using GAN
_Nov 2023 ‚Äì Dec 2023_
- Model Design and Tools: Utilized TensorFlow and Keras to construct and train a Generative Adversarial Network (GAN) with a detailed generator and discriminator architecture, aiming to generate realistic human face images.
- Dataset and Preprocessing: Employed a face-mask-lite dataset containing 9,090 images, preprocessed using OpenCV for color correction and resizing, followed by transformation into tensor slices for efficient batch processing during training.
- Training and Results: Over multiple training epochs, refined the generator's ability to produce convincing face images, achieving increasingly realistic results as evidenced by discriminator feedback, which assessed the artificial images' similarity to genuine data distributions.
- [For more Details](./GAN.html)

### Causality in Machine Learning
_Oct 2023 ‚Äì Nov 2023_
- **Data Simulation and Visualization:** Simulated causal relationships between variables A and B, visualizing data with scatter plots and correlation analysis to explore initial indications of causality.
- **Statistical Techniques:** Applied linear regression to establish causality, using correlation metrics and regression coefficients to predict changes in B as a result of changes in A.
- **Causal Inference Application:** Demonstrated the use of causal inference in machine learning to enhance model interpretability and feature selection, significantly improving model generalization capabilities across varied datasets.
- [For more Details](./Causal.html)

### Time Series Forecasting for Product Sales
_Aug 2023 ‚Äì Sept 2023_
- Data Analysis and Preparation: Analyzed five years of sales data (2013-2017) for 50 products across 10 stores. Preprocessed data by creating time-related features and splitting into training and test datasets.
- Model Implementation and Techniques: Employed multiple time series forecasting models, including Seasonal Naive, Holt-Winters, ARIMA, and Linear Regression, using Python libraries like statsmodels and sklearn.
- Results and Evaluation: Achieved best forecast accuracy with Holt-Winters model, showing significant improvement over the baseline Seasonal Naive model. Evaluated forecasts using MAE, RMSE, and MAPE metrics.
- [For more Details](./TimeSeries.html)

### Feature Engineering in Data Science
- Data Analysis and Cleaning: Analyzed World Happiness Report data to predict happiness scores using statistical methods and Python libraries like Pandas and Seaborn. No missing or inconsistent values were found.
- Feature Selection and Evaluation: Applied multiple feature selection techniques including p-value analysis, correlation matrices, and machine learning models like Random Forest to identify significant predictors of happiness.
- Model Optimization and Validation: Optimized the predictive model by removing insignificant variables, leading to better model performance and accuracy in predicting country happiness scores.
- [For more Details](./FeatureEngineering.html)

## Technical Skills üíª

- **Programming Languages:** Python, R, SQL, PySpark
- **Orchestration Tools:** Apache Airflow, Talend, dbt
- **Data Science Libraries:** Pandas, Sci-kit learn, NumPy, TensorFlow, Matplotlib, Seaborn
- **Databases:** MySQL, SQL Server, PostgreSQL, Pinecone Vector DB
- **Data Cloud Services:** BigQuery, Amazon Redshift, Amazon S3, Snowflake, Amazon EC2, Google Cloud Storage
- **Visualization Tools:** PowerBI, Tableau, Looker

## Data Proficiency

### 1. Data Collection
I have demonstrated proficiency in gathering data from diverse sources including APIs, web scraping, and public data repositories. This has allowed me to work with real-time data feeds and historical data archives, enhancing the breadth and depth of analytical projects.

### 2. Data Cleaning
My approach to data cleaning involves handling missing values, removing duplicates, and correcting errors, which ensures the integrity of the data for reliable analysis. I employ tools like Pandas and NumPy for efficient data manipulation.

### 3. Data Exploration
I excel in exploratory data analysis using statistical summaries and visualization tools such as Matplotlib and Seaborn. This helps in understanding underlying patterns and anomalies in the data, guiding further analysis.

### 4. Statistical Analysis
I apply statistical methods to derive meaningful insights from data, including hypothesis testing and regression analysis. This allows me to validate data models and hypotheses effectively.

### 5. Machine Learning
I am skilled in building predictive models using supervised and unsupervised learning algorithms. Techniques like regression, classification, and clustering are part of my repertoire, executed with Scikit-learn and TensorFlow.

### 6. Deep Learning
My expertise extends to deep learning frameworks such as TensorFlow and Keras, where I build and train advanced models like neural networks to tackle complex datasets and problems, achieving high accuracy.

### 7. Natural Language Processing
I utilize NLP techniques to analyze textual data, applying sentiment analysis, text classification, and tokenization to extract and process unstructured data for various applications.

### 8. Data Visualization
I create compelling visual representations of analysis outcomes using advanced visualization tools like Tableau and Power BI, making complex results accessible and understandable.

### 9. Big Data Technologies
Experienced with big data platforms like Apache Hadoop and Spark, I manage and analyze vast datasets efficiently, ensuring scalability and performance of data processing operations.

### 10. Data Warehousing
I design and implement data warehousing solutions using SQL and NoSQL databases, optimizing data storage, retrieval, and management for enterprise-level applications.

### 11. Data Integration
I integrate data from various sources and formats to create cohesive and comprehensive datasets, facilitating more effective analysis and insights.

### 12. Feature Engineering
I enhance machine learning models by engineering and selecting relevant features, improving model accuracy and performance through thoughtful analysis of input variables.

### 13. Model Optimization
I optimize data models using techniques like grid search and cross-validation to find the most effective model parameters, ensuring peak performance.

### 14. Model Deployment
I deploy machine learning models into production environments, using platforms like AWS and Azure, to bring data science solutions directly to end-users in real-time applications.

### 15. Automation of Data Processes
I automate repetitive data processing tasks using scripting and workflow automation tools, increasing efficiency and reducing the likelihood of human error.

### 16. AI Ethics
I consider ethical implications of AI and strive to implement solutions that are fair, transparent, and privacy-conscious, ensuring that data science practices benefit all stakeholders.

### 17. Collaborative Data Science
I work collaboratively in team settings, using version control systems like Git and collaborative platforms like JupyterHub, to build data science solutions that leverage collective expertise.

### 18. Continuous Learning
I am committed to continuous professional development, staying abreast of the latest trends and technologies in data science through ongoing education and training.

### 19. Project Management
I manage data science projects from conception to deployment, ensuring they meet timelines, budgets, and project specifications, and deliver substantial business value.

This extensive showcase of my data science expertise underscores my ability to handle complex data challenges, making me a valuable asset to any data-driven organization.

